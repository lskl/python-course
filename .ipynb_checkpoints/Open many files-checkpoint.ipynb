{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to open a list of files and concatenate into a single pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows how we can open a list of files and have a single table of data in pandas. \n",
    "\n",
    "### We use the function `pandas.concat()`, which puts one data frame _after_ the other, that means that the _columns_ must be the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we have three csv files, with three days of data, one day each. They have columns for a timestamp, temperature and relative humidity. The files are in a subfolder named ***three\\_files***.\n",
    "\n",
    "We will open all files, one after the other inside a `for` loop, and concatenate them into a single dataframe. In the end, we can save that file to a new dataframe. \n",
    "\n",
    "Also, we will only select one column, the temperature, to show how this selection can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/three_files.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of the files names to iterate over them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Write them to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_read = [ '2018-04-18.csv', '2018-04-19.csv', '2018-04-20.csv' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works if there are not many files, and also if there are many different files in the same folder, but we don't want to read all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Read all the files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-04-18.csv', '2018-04-20.csv', 'some_empty_file.txt', '2018-04-19.csv']\n"
     ]
    }
   ],
   "source": [
    "files_to_read = os.listdir( 'three_files/' ) # returns list with everything in that directory\n",
    "print( files_to_read )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works if we want many files, all of them. If you want to filter some in or out, you need to read as shown, and then delete elements from the list. \n",
    "\n",
    "For example, you can select only files with a `.csv` extension adding the following line after reading the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-04-18.csv', '2018-04-20.csv', '2018-04-19.csv']\n"
     ]
    }
   ],
   "source": [
    "files_to_read = os.listdir( 'three_files/' ) # returns list with everything in that directory\n",
    "\n",
    "files_to_read = [ name for name in files_to_read if '.csv' in name ] # Select only those with .csv as part of their name\n",
    "\n",
    "print( files_to_read )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a loop and concatenate all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: _normal_ `for` loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an empty data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe1 = pd.DataFrame( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `for` loop to read each file and concatenate into the big data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_file in files_to_read:\n",
    "\n",
    "    current_df = pd.read_csv( 'three_files/'+current_file ) # Care for the subfolder or path!\n",
    "\n",
    "    current_df = current_df[ [ 'Date and Time', 'Temp. (째C)' ] ] # Select only the columns that we want\n",
    "    \n",
    "    big_dataframe1 = pd.concat( [ big_dataframe1, current_df ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataframe1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we specify the columns while reading the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe2 = pd.DataFrame( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_file in files_to_read:\n",
    "\n",
    "    current_df = pd.read_csv( 'three_files/'+current_file, usecols=[ 'Date and Time', 'Temp. (째C)' ] )\n",
    "        \n",
    "    big_dataframe2 = pd.concat( [ big_dataframe2, current_df ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataframe2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe3 = pd.concat( [ pd.read_csv( 'three_files/'+current_file, usecols=[ 'Date and Time', 'Temp. (째C)' ] )  for current_file in files_to_read] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataframe3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can break that big line into several for better reading, python keeps track of open parenthesis and brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe3 = pd.concat( [ pd.read_csv( 'three_files/'+current_file, \n",
    "                                          usecols=[ 'Date and Time', 'Temp. (째C)' ] )  \n",
    "                             for current_file in files_to_read] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataframe3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending which method you used, you can save to a file activating the corresponding line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_dataframe1.to_csv( 'big_table.csv' )\n",
    "# big_dataframe2.to_csv( 'big_table.csv' )\n",
    "# big_dataframe3.to_csv( 'big_table.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common options that you might want to use are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_dataframe1.to_csv( 'big_table.csv', sep=';', index=False )\n",
    "# big_dataframe2.to_csv( 'big_table.csv', sep=';', index=False )\n",
    "# big_dataframe3.to_csv( 'big_table.csv', sep=';', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
